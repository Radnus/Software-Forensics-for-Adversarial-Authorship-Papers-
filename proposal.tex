%%%       aums.sty (Masters Thesis)
%%%       auphd.sty (Ph.D. Dissertation)
%%%       auhonors.sty (Honors Scholar)

%%%To use it, please edit the necessary options, title, author, date, year, keywords, advisor, professor, etc. 

\documentclass[12pt]{report}
%\usepackage{aums}       % For Master's papers
\usepackage{auphd}     % Rodney edited the aums style to auphd
\usepackage{ulem}       % underlining on style-page; see \normalem below
\usepackage{url}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{graphicx}
\graphicspath{ {./images} }
\usepackage{todonotes}
\usepackage{mathtext}
\usepackage{listings}
\usepackage{pgfgantt}
\usepackage{comment}
\usepackage{adjustbox}
\usepackage{outlines}
\usepackage[table]{xcolor}
%\usepackage{natbib}
%%%%%Format rules: Normal margins are 1 in. If you need to print with 1.5in margins, uncomment the line below
%\oddsidemargin0.5in \textwidth6in

%% If you do not need a List of Abbreviations, then comment out the lines below and the \printnomenclature line.
%%for List of Abbreviations information:  (see http://www.mackichan.com/TECHTALK/509.htm  )
\usepackage[intoc]{nomencl}
\renewcommand{\nomname}{List of Abbreviations}   	       
\makenomenclature 
%% don't forget to run:   makeindex ausample.nlo -s nomencl.ist -o ausample.nls
%% Also, if 

% May want theorems numbered by chapter
\newtheorem{theorem}{Theorem}[chapter]

% Put the title, author, and date in. 
\title{Software Forensics for Adversarial Authorship}
\author{Rodney Visser} 
\date{[Insert date of graduation, e.g., Aug 1, 2022]} %date of graduation
\copyrightyear{2022} %copyright year

\keywords{Software Forensics, Threat TTPs, Digital Provenance, Machine Learning, Deep Neural Networks, Random Forrest Classifier, Threat Intelligence, Authorship Attribution}

% Put the Thesis Adviser here. 
\adviser{David Umphress}

% Put the committee here (including the adviser), one \professor for each. 
% The advisor must be first, and the dean of the graduate school must be last.
% WHY IS THIS NOT SHOWING UP ON THE TITLE PAGE???
\professor{David Umphress, Chair, Senior Advisor, Auburn Cyber Research Center}
\professor{Daniel Tauritz, Associate Professor of Computer Science and Software Engineering}
\professor{James Cross, Professor of Computer Science and Software Engineering}
\professor{Drew Springall, Assistant Professor of Computer Science and Software Engineering}

\begin{document}
\begin{romanpages}      % roman-numbered pages 
\TitlePage 

\begin{abstract} 
Software forensics in computer science can often be used to determine intellectual property rights and it provides potential for threat attribution.  Risks from malicious software and the software supply chain are becoming increasingly an issue as code gets more complex and attackers continuously outpace defenders in the digital domain.  The software development process has changed significantly and threats have been on the bleeding edge of this maturity in terms of capability and obfuscation. The history and modern motivation for such analysis of software is present and includes commercial and government organizations.  This research investigates current static and dynamic methods of performing software forensics and improves on these methods by utilizing multi-dimensional analysis to detect semantic differences between two versions of a similar software code and then applying models in order to predict future changes in behavior.
\end{abstract}

%\begin{acknowledgments}
%Put text of the acknowledgments here.
%\end{acknowledgments}

\tableofcontents
\listoffigures
%\listoftables

\printnomenclature[0.5in] %used for the List of Abbreviations
\end{romanpages}        % All done with roman-numbered pages


\normalem       % Make italics the default for \em
%*********************************************************************
%*********************************************************************
%Chapter One (CH1)
%*********************************************************************
%*********************************************************************
\chapter{Introduction}  
\label{chap:one}

A quickly growing use case of software forensics is authorship attribution, the process of attempting to identify the likely authorship of a software sample given a collection of software whose authorship is known.  Convention points to the use of a subfield of digital forensics, software forensics,  to apply authorial context to the providence of malicious software.  The categorization and mapping of key properties extracted from a suspect artifact can be used to select candidate matches from a pool of legitimate artifacts.  We aim to provide a glimpse into the genealogy of a malware sample through the lens of software forensics.

Currently, reverse engineering software artifacts suspected of being malicious code remains a labor-intensive and manual task, despite advances in automated programming understanding.  Static and dynamic analysis tools provide insight into software structure and behavior, but the ultimate determination of what is a malicious artifact relies heavily on the skills and experiences of individual forensic investigators.  Further complicating the process, attackers have also begun to place false flags within the technical breadcrumbs that are commonly left behind after a cyber attack.  

A cost effective example of malware delivery is through the use of phishing emails, where the content of the email tries to entice the recipient to click a URL linking to a malicious web site or downloading a malicious attachment. Analysts attempting to provide intelligence on such activities quickly find that the ever increasing volume of phishing emails circulating daily is overwhelming and the most effective phishing techniques are often not caught because of their use of the proper application of backstopping.  Therefore, intelligence gathered within this area is only representative of only a small sample at a single point in time, not of the global picture of the problem.  Additionally, analyses have revealed that authorship attribution on this type of malware delivery method have provided linkages to the same author, but that it is unlikely that the authorship-based clustering algorithms have managed to group together all spam produced by each group.  Said in another way, this is not a sustainable answer to authorship attribution on this type of malware delivery method on it's own because of the low rate of recall within APT groups.  This problem of high precision with low recall has been faced in past authorship research \cite{li2017association}.  In broader terms, the issue of authorship attribution of malicious code and the various delivery methods suffer from problems related to precision and recall when analyzed on their own.  This problem we propose can be assisted by multi-dimensional analysis using a novel framework.

A key issue in authorship attribution for cyber attacks is the lack of specific knowledge about technical capabilities, motivation, policies, and laws that currently govern this area.  The difficult technical side of attribution is further escalated by serious legal and policy questions about when and how to accuse governments of responsibility for cyber attacks.  Within the area of technical capabilities and motivations for groups that have been labeled as Advanced Persistent Threats (APT)s by commercial cyber security firms, there are sweeping differences in the arrangement, categorization, and number of named threats from nation states or criminal enterprises. \cite{romanosky2019private}  Below in Table 1.1 we provide a snapshot of the disconnect between leading cyber threat intelligence firms that track and publish intelligence on named APTs.

\begin{table}[h!]
  \centering
    \caption{Named APTs}
    \label{tab:table1}
    \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{l|c|c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \textbf{Country} & \textbf{FireEye} & \textbf{CrowdStrike}  & \textbf{Kaspersky} & \textbf{Dell SecureWorks}  & \textbf{Cisco Talos}\\
      \hline
      China & 20 & 40 & N/A & 5 & 9 \\
      Russia & 3 & 3 & N/A & 6 & 3 \\
      Iran & 3 & 7 & N/A & 1 & 3 \\
      North Korea & 1 & 4 & N/A & 2 & 2 \\
      Criminal / Terrorist & 10 & 29 & N/A & 3 & 1 \\
      Other & 2 & 1 & N/A & 2 & - \\ 
      Unknown/Undisclosed & 8 & 1 & N/A & - & 1 \\
      \hline
      Total & 47 & 85 & 36 & 19 & 19\\
    \end{tabular}
  \end{center}
\end{table}

Although politics may largely determine whether attributions are made public, there is a need for a framework in which cyber attacks are attributed to states in a means governed by legal standards \cite{eichensehr2020law}.  Experts on the topic of cyber threat attribution are quick to call for greater levels of regulation and policy that govern the world's critical infrastructure and economies, but for the most part, worldwide leaders in key positions do not understand the issues presented to them, the proper information is not made available, or the terrain of navigating the geopolitical landscape on this issue in the public eye is deemed risky.

A prime example of state sponsored cyber espionage and influence operations is the unauthorized access and disclosure of the Democratic party's email in 2016 by a Russian State backed hacker group commonly referred to as Fancy Bear.  The main point of dissemination for this operation was a self proclaimed Romanian hacker called Guccifer 2.0.  Toni Gidwani, director of research operations for ThreatConnect, said: ``It would suggest to us that the operators of the Guccifer 2.0 persona were not the actors who breached the DNC.  You’re looking at the operations guys who don’t have the same technical credibility as these very sophisticated actors who exploited these networks. You've got a lot of cooks in this kitchen here, not just one actor.'' \cite{zager2016response}

This type of misdirection campaign for state sponsored hacking is considered common place and automated single-dimension attribution techniques are easily guided in the wrong direction.  Recent application of technology in the realm of source code authorship attribution methods have accuracy above 88\%, but adversarial learning attack methods drop the rates of attribution to around 1\% \cite{abuhamad2018large}, \cite{caliskan2015anonymizing}, \cite{quiring2019misleading}. 

For these reasons, attribution must be thought of as a multi-dimensional issue that draws on multiple sources of information available, including technical forensics, human intelligence, signals intelligence, history, and geopolitics, among others \cite{lin2016attribution}.  If successful, the attribution of successful adversarial attacks from code left behind on an infected system could enable software forensics to be leveraged in order to be fight advancing and evolving threats. 

\begin{comment}
Why it is important 
    - expert opinions - if only we could apply attribution
	    2016 presidential election
	    Olymipics hack (Wired)
	    Sony hack

    - number statistics
        attack has a substantial effect on two recent attribution methods,  whose accuracy drops from over 88 percent to 1 percent under attack.
    
        [1] M. Abuhamad, T. AbuHmed, A. Mohaisen, and D. Nyang. Large-scale and language-oblivious code authorship identification. In Proc. of ACM Conference on Computer and Communications Security (CCS), 2018.
@inproceedings{abuhamad2018large}

        [9] A. Caliskan, R. Harang, A. Liu, A. Narayanan, C. R. Voss, F. Yamaguchi, and R. Greenstadt. Deanonymizing programmers via code stylometry. In Proc. of USENIX Security Symposium, 2015.
@inproceedings{caliskan2015anonymizing}

	DU "I don't get a scense of the degree to which the problem is relevant.  Please provide information which points to the impoertance of solving the problem.  Substantiate with facts."

A. INSERT Ref to "ODNI_A_Guide_to_Cyber_Attribution"
"Establishing attribution for cyber operations is difficult but not impossible.  No simple technical process or automated solution for determining responsibility for cyber operations exists.  The painstaking work in many cases requires weeks or months of analyzing intelligence and forensics to assess culpability.  In some instances, the IC can establish cyber attribution within hours of an incident but the accuracy and confidence of the attribution will vary depending on available data."


Addin Bruce Scnider reference on threat attribution and one from ex-Microsoft Executive that was the Cyber Czar and incorrect about China." Howard Anthony Schmidt died in 2017 at the age of 67

E G See, Rt, Philip Hon, Hammond
I unequivocally condemn these cyber attacks [on Sony] and am deeply concerned at the findings of the US investigation, which seems to provide further evidence of North Korea's blatant disregard for international norms and obligations
Foreign & Commonwealth Off
Posted: 2014-12-19

E G See, Bruce Schneier
I am deeply skeptical of the FBI's announcement on Friday that North Korea was behind last month's Sony hack. The agency's evidence is tenuous, and I have a hard time believing it
Posted: 2014-12-22

E G See, Jack Goldsmith
sony-hack-attribution-problemsand-connection-domestic-surveillance (noting that "the 'evidence' is of the most conclusory nature" and "on its face . . . shows only that this attack has characteristics of prior attacks attributed to North Korea
Posted: 2014-12-19
\end{comment}

\section{Software Forensics}
  The history of software forensics is a relatively brief one when compared to other forensic sciences.  It began with methods for finding similarities in software by comparing code through hashing, statistical analysis, text matching, and tokenization.  These methods compared software code at a primitive level by ingesting sources and producing a single measure indicating similarity.  These measures were not accurate enough to be admissible in modern courts because the algorithms used to find them could be easily fooled by simple substitutions.  ``The discipline of computer forensics appears to be struggling over methods and practices that will meet the courts’ “standards” for scientific evidence" \cite{meyers2005digital}.

By first examining similarity of a software artifact to other artifacts that have been previously observed, investigators can frame deeper questions, such as investigating new or changed capabilities.  For example, clues as seemingly insignificant as the format of calendar dates or the language used in text strings can be used to help identify demographic origins.  Level of sophistication, control flow patterns, stylistic flourishes, obfuscation techniques, and unique defects have the potential to signal the education and skill level of an artifacts creator or creators, perhaps going so far as to call out our artifact authorship given a collection of samples from a known author or authors.  Indirect information of this type, if available and used properly, offers a context so that investigators are not working in a vacuum, where each suspect artifact has been treated as a never-before-seen item.

The challenge becomes one of how to automate the use of attributes as figurative fingerprints capable of leading software forensic investigators to artifact lineage and pedigree.  Principal unresolved issues include how to identify which attributes determine similarity among artifacts, how to assess the trust of information inferred from the use of attributes, and how to establish a sufficiently reliable approach to satisfy legal standards.

\section{Problem Statement}
\label{sec:ProbState}
Within the questions of \emph{what, when, where, who, and how} for digital forensic investigations, answering the who question is frequently the most elusive.  The strategic aim of this research is to assist in answering this important question.  The tactical objectives include a survey of current state-of-the-art techniques in adversarial authorship using software forensics and the application of machine learning to automate and innovate analysis.

Software-assisted detection allows vast collections of artifacts to be compared to each other, making successful detection much more likely than traditional manual methods.  We refer to these first generation software-assisted means of detection as Single Dimensional Software Correlation.  This method can be thwarted by simple compiler optimizations and anti-forensic techniques.  Differences in hashing and mapping methods can cause a significant increase in false negatives count.

The motivation to use more focused and robust software forensic techniques is growing at an expanded rate in order to keep up with the adversarial techniques malware authors use to obfuscate their code.  Cyber threat actors for the most part are out pacing the defenders at an increasing rate, modern software forensics tools, techniques, and procedures are growing, but not fast enough to lessen the gap with threats.  In order to keep pace with intermediate and advanced level threat actors, novel techniques must be employed to find, track, and project how threats are evolving.  It is our belief that adversarial authorship using software forensics can allow us to do this.

%********************************************************************
%********************************************************************
%Chapter Two (CH2)
%********************************************************************
%********************************************************************
\chapter{Literature Survey}
\label{chap:two}
Using software forensics to track and plot the actions and potential growth of cyber threat actors includes problematic factors such as: lowered barriers of entry in terms of technical competence, malware as a service platforms, increasing levels of sophistication, and an rapidly expanding attack surface.  The development of a novel graph pruning technique has shown that software correlation can be used to understand how malicious code has evolved over the years, and in particular, how different instances of malicious code relate to one another.  Researchers established an inheritance relationships between different instances of malware based on temporal information and key common phrases identified in the malware descriptions and an extension of this research has the potential to show that software correlation can be used to inspect known examples of malware in order to gauge how threats and their code bases are evolving \cite{gupta2009empirical}.

Authorship attribution has its roots in plagiarism detection, which is the process of locating instances of literary theft within traditional documents.  The word \emph{plagiarism} dates back to the first century AD with the Roman poet Martial, one of the most prominent poets of his time.  Martial discovered that his work was being copied and provided wholesale without proper attribution.  Unlike other authors in a similar predicament at the time, Martial was not content to stand by and other take credit for his work.  He wrote several verses directed to his copycats.  One in particular was aimed at a man named Fidentinus \cite{martial:1958}:

\begin{quote}
``FAME HAS IT THAT YOU, FIDENTINUS, RECITE MY BOOKS TO THE CROWD AS IF NONE OTHER THAN YOUR OWN.
IF YOU’RE WILLING THAT THEY BE CALLED MINE, I’LL SEND YOU THE POEMS FOR FREE.
IF YOU WANT THEM TO BE CALLED YOURS, BUY THIS ONE, SO THAT THEY WON’T BE MINE." 
\end{quote}

In one of his poems he used the latin word \emph{plagiarus} to describe a literary thief.  In his time, the term meant to kidnap, and it specifically related to either the kidnapping of one's slaves or to take a free person and make them into a slave.

The modern day widespread use of computers connected to the Internet has eased the task of the plagiarist.  A great deal of cases of plagiarism can be found in academia, where documents are typically essays or reports, but plagiarism can be found in virtually any field, including software engineering. \cite{!stealsc:2012}

In the case of software plagiarism, advanced obfuscation techniques have made automated detection at scale increasingly difficult because of the ease of change in the structure of the code while preserving the code semantics \cite{xu2020revisiting}.  As an example, software compilers can easily configured to obfuscation techniques to change the assembly code, resulting in a low similarity score.  For prototypes that have been seen to be resilient to advanced code obfuscation, there is a problem of scale.  Most graph-based approaches are time consuming since it is a NP-hard problem.  Within an example of semantics-based approach using graphs, it took an hour in  the  comparison \emph{thttpd} and \emph{sthttpd}, and half a day in the comparison between \emph{Gecko} and \emph{Firefox} \cite{luo2014semantics}.  Given the increased application of advanced obfuscation techniques to malware, the scalability to process samples becomes a critical need.

\begin{comment}
DU "I have a tough time understanding the link between plagiarism and author attribution.  Plagiarism is demonstrated by proving that a suspect artifact sufficiently resembles any other artifact.  It does not imply that we can not infer knowledge about the artifact based on the original source.  I think you need to tighten your chain of logic in linking plagiarism to authorship attribution...or eliminate the plagiarism piece altogether.

	DU "Plagiarism = the suspect artifact is a copy of something else
	    You want = Who is the originator and, if we have seen it before, what do we know about the original"

	plagiarism section - where is the original source
		* link with technical example of an attribution problem

	Sandworm - Andy Greenberg Wired Magazine - 2018 Olympics Russian Cyber Attack - South Korea
		Miss-direction using false flags

Here is how attributions done and how can we do it better?
\end{comment}

\begin{comment}
STUXNET - why is authorship attribution of 2 nation states working together to on a important project important
		more history on the attribution side
			(why is authorship attribution ***ch.1*** )

	DU "I don't see where you describe how stuxnet was understood because of its origins were traced to an original.  In other words, I did not see a plagiarism or an authorship attribution aspect in this description."
\end{comment}

The devastating cyber attack referred to as the NotPetya worm is an example of the greater level of need for advancing software forensic tools in order to better help determining adversarial attribution.  The NotPetya worm was created by a group of Russian military intelligence hackers known as Sandworm, and was intended as a climactic strike against Ukraine in the years-long cyberwar Russia had carried out against its southwestern neighbor.  This worm presents an interesting case because of the unique combination of using stolen National Security Agency hacking capabilities, an open-source credential-harvesting tool called \emph{Mimikatz}, and the hijacking of a update system within a common piece of Ukrainian accounting software that was used used by practically every company that filed taxes or had business ties in the country.  \cite{greenberg2018untold}

\begin{comment}
Shadow Brokers, EternalBlue, EternalRomance
    ETERNALROMANCE is a SMB1 exploit over TCP port 445 which targets XP, 2003, Vista, 7, Windows 8, 2008, 2008 R2, and gives SYSTEM privileges (MS17-010)
    ETERNALBLUE is a SMBv2 exploit for Windows 7 SP1 (MS17-010)

WannaCry ransomware used this exploit to attack unpatched computers.
\end{comment}

\begin{comment}
The Stuxnet worm is an example of the greater levels of need for advancing software forensic tools in determining adversarial attribution. \cite{parker2011stuxnet}  One area of Stuxnet was the use of a modified Step7 library file, named s7otbxdx.dll, to communicate with a Siemens Programmable Logic Controller (PLC) (see Figure \ref{fig:stuxnet-modified-s7otbxdx.dll}).  

\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{images/modified_Step7.jpg}
	\caption{Stuxnet’s modified s7otbxdx.dll file \protect\cite{falliere2010exploring}}
	\label{fig:stuxnet-modified-s7otbxdx.dll}
\end{figure}

Stuxnet's modified s7otbxdx.dll forwards 93 of the original 109 exports to the real DLL, renamed to s7otbxsx.dll, for processing.  16 exports were intercepted by the custom DLL in order to modify data being sent to or returned from the PLC without the operator of the PLC realizing it. It is also through these routines that Stuxnet was able to hide malicious code on the PLC itself.
\end{comment}

In order to use software forensics to track advancing threats like that of NotPetya, the software forensics engineer needs to break the inputs into objects suitable for comparison and apply structure to these objects.  This structure can then be used to determine which objects exist across various versions and which do not.  This is not a simple task since the differences in high-level language constructs and structure, including code comments, are commonly not found in the compiled versions of the malicious software.  Techniques used to identify the fingerprints of malicious software authors come from a variety of sources and modern plagiarism detection techniques can be used to highlight patterns. 

\section{Single Dimensional Software Correlation}
Single Dimensional Software Correlation takes a single input source and uses that source to apply structured analysis.  This analysis determines the similarity of source or binary code, by comparing their raw text, cryptographic hashes, and tokens.  The result is a single measure that indicates the degree of similarity.  These measures are not accurate enough to be admissible in court of law because they are not definitive.  Questions arise because the algorithms can be fooled by, for example, simple substitutions in the code with representative fixes.  Similarly, the problem of instruction reordering can be solved though grouping using the variable tracing and sorting method \cite{oh2009fight}.

\cite{zeidman2012detecting} developed algorithms that look at the basic elements of code in order to find which elements are correlated to each other.  He proposed an algorithmic method that extracts program elements that are common in the samples being compared.  These methods keep each of the data structures that are found to have entries corresponding to program elements of a distinct program element type represented by program strings or program identifiers.   From that, elements are extracted based on a program object code file using a text converter to convert the program object code to text sequences by solely determining byte by byte whether the sequences represent characters.  Then a calculation of a correlation score based on the similar entries is done that is comprised of a number of similar strings and a number of similar identifiers.

\begin{comment}
The major drawback to this work is the high number of false positives that result from the comparison.  Efforts to improve accuracy included interpreting the elements being compared to eliminate reasons for correlation unrelated to copying, such as common algorithms, third-party code, common identifier names, common author, and automatic code generation.

DU Comment = citation(s) needed
\end{comment}

Another single dimensional software correlation technique is analysis of code comments.  Once analysis has been performed using single dimension software forensic tool and/or procedure, an analyst can then begin looking at subjective evidence such as comments in the code.  Fake copyright notices, open source notifications, or programmer names added to source code after copying took place, in order to disguise the copying, are not uncommon in real-world cases of code theft \cite{sfbook:2011}.  This has been shown in practice to support a number of different challenges and benefits.  Challenges arise in the ways that code comments are written using natural language, which complicates automated means to understand the intent of comments even when armed with the latest Natural Language Processing (NLP) techniques \cite{artsci:2015}.  As a benefit, code comments contain a rich amount of information that can be leveraged to improve attribution.  Analyzing free-form and semi-structured code comments can assist in the unique identification of characteristics and content of code comments.

The value of code comment analysis is improved when presented with strong pieces of supplemental data.  Information such as how an organization distributes its code, details of the software development life-cycle can possibly emerge.  This gives the potential to identify the programmers who authored the code.  

There is also work being done on data sets of different programming languages (Java or C++) of varying difficulty (6 to 30 candidate authors) to demonstrate the effectiveness of the Source Code Author Profiles (SCAP) approach.  This is based on analysis of byte-level contiguous sequence profiles in order to represent a source code author’s style.  \cite{IFIP:2006} This method has potential to show effectiveness of the model and how it is not severely affected by the absence of comments in the source code, a condition usually met in cyber-crime cases.

The analysis of malicious code authorship and true functionality without the assistance of the underlying source code makes single dimensional software correlation difficult and a prime target for deception.  Comparing code functionality is a difficult problem that has yet to be effectively shown by any algorithm within a reasonable time.  For this reason, the process of applying attribution to a code's author is still mostly manual.

\subsection{Malware Detection}
Within this area of research the topic of accurately detecting malware in order to apply attribution is important and relevant work within malware detection can be used to guide better results within authorship attribution.  We describe this research in two different types, syntactic vs semantic analysis.  An easy way to describe the differences in these techniques is a pattern matching approach and a trait detecting approach.

Syntactic detection of modern malware is fraught with issues, and a key one is the use of self-mutating malware.  A good example that describes the cat and mouse game of malware detection is syntactic analysis of payload generation and encoding capabilities of the open source exploitation framework metasploit.  Shikata-Ga-Nai is a Japanese language phrase meaning "it cannot be helped" or "nothing can be done about it" and for many years this was an accurate description of the ability of syntactic analysis tools to trigger on this specific method of encoding that is built into the metasploit framework.  At is core, it is a polymorphic xor additive feedback encoder.  This encoder offers three features that provide advanced protection when combined.  First, the decoder stub generator uses metamorphic techniques, through code reordering and substitution to produce varied output each time it is used.  This makes triggering on just the shellcode very difficult, especially if unique parameters are leveraged.  This is implemented using loops with a user definable counter.  Second, it uses a chained self modifying key through additive feedback. This means that if the decoding input or keys are incorrect at any iteration then all subsequent output will be incorrect.  Third, the decoder stub is itself partially obfuscated via self-modifying of the current basic block as well as armored against emulation using Floating-Point Unit instructions.  

Some currently name and tracked cyber threat groups still leverage the Shikata-Ga-Nai encoder in their operations.  APT20, a suspected Chinese nation state sponsored threat group that still utilize this method to encoded some of their payloads.  This group has a primary focus on stealing data, specifically intellectual properties.  Other named groups include APT41 and FIN6.  APT41 has been seen using this encoder within custom developed backdoors.  APT41 is a Chinese cyber threat group that has been observed carrying out financially motivated missions coinciding with cyber-espionage operations.  The financially focused threat group FIN6 also uses this encoding method to carry out some of their missions, and they have historically relied upon various publicly available tools. These missions largely involve theft of payment card data from point-of-sale systems. 

Static Malware Detection by the use of mechanisms to detect string signatures, byte-sequences, n-grams, syntactic library calls, control flow graph and opcode frequency distribution of known malware have helped keep pace with obfuscation, but some of these measure are trait detecting approaches.  Semantic malware detection measures that leverage intermediate languages like \cite{christodorescu2005semantics}, \cite{ranjan2016boolean} have been shown to provide greater levels of resilience against the polymorphic capabilities of modern malware.  These methods use LLVM generators which convert machine code to simplified forms in order to aid in semantic analysis that can be leveraged in identification of authorship traits.  Next generation malware will by be characterized by the intense use of polymorphic and metamorphic techniques aimed at circumventing the current malware detectors, based on pattern matching. \cite{bruschidetecting}

\section{Multidimensional Software Correlation}
Multidimensional software correlation is the process of dividing software code into separate parts in order to determine which elements are similar.  One of the key elements to applying this correlation is the ability to filter and interpret the correlations in order to eliminate false positives.  The state of research of semantic data models being leveraged for machine learning has shown promise in helping identify similar elements for correlation.  One example of this work is the concept of traceability being applied using machine learning within safety-critical domains for source code and other artifacts using Word Embedding and Recurrent Neural Network (RNN) models to generate trace links.  RNN models use word vectors to learn the sentence semantics of requirements artifacts.  An RNN system that uses Bidirectional Gated Recurrent Units (BI-GRU) has shown promise for the tracing task.  BI-GRU, in this instance, significantly out-performed state-of-the-art tracing methods including the Vector Space Model and Latent Semantic Indexing.   This provides us an example of a solution that leverages deep learning to incorporate artifact semantics into a novel solution. \cite{guo2017semantically}

An important piece of addressing attribution using software correlation is the network path and protocol capabilities.  Research being done within the area of time-series forecasting methods for cyber attacks, from network telescopes, honeypots, and automated intrusion detection/prevention systems is limited to awareness of predesignated items within a temporal scope that can be easy to miss and hard to collect.  ``To enhance awareness about specific threats, it is vital to uncover associated and, ideally, causal factors for cyber attacks"  \cite{DBLP:journals/corr/BakdashHZMTSHD17}.  For our research endeavor, this data can be used to assist in attribution based on past observation of transit data path, means, and capabilities.  These supporting factors can be used in order to further judge breadth, depth, and positioning of future attacks in traditional and new environments that threats are working towards having similar capabilities that exist in client-server environments.

Provenance, a word that originates from art, refers to the chronology of location and ownership.  A detailed provenance can be used to establish that a piece of art is not a forgery or has not been stolen.  Recently, the term provenance has also been adopted and applied to other fields, including computer science, where it refers to having knowledge of all the steps involved in producing a scientific result, from experiment design through acquisition of raw data and all the subsequent steps of data selection, analysis, and visualization \cite{provenance:2011}.

The concept of provenance can also be applied to multidimensional software correlation.  The tracing of provenance in software development has become increasingly more important to tracking vulnerabilities and threats.  Models of provenance developed from observing software during its natural life cycle can be used to educate researchers on how code evolves and mutates over time.  The relation between a large file and LOC objects is very sparse and indexing can allow the relations to mapped as clusters of LOC and their containing files.  Using these observations, an analyst is able to observe statistical trends of modifications made to files over time and see changes in sparse structures and natural growth patterns throughout a software development life cycle.  In a typical scenario, files exhibit rapid initial growth with code being added in large chunks, and then when the changes of the software are in place, small bug fixes are the majority of modifications thereafter.  By tracking the unique relationship between file size and lines of code, an analyst can map codelets as code patches with co-migratory patterns in files.  \cite{provenance2:2014}  For instance, a generative model that uses a Bayesian game to assist in Active Malware Analysis (AMA) has shown to have strong statistical results in identifying relations in software provenance between malware families \cite{sartea2020bayesian}.  

Traditional grammar-based analysis techniques used to detect plagiarism have been adapted for use in code source plagiarism detection (\cite{kustanto2009automatic}, \cite{lesner2010novel}, and \cite{jadalla2008pde4java}).  Code, like speech, consists of patterns that can link the author to the product.  The langage Prolog offers advantages for a thorough analysis in two main parts.  In one part, it natively provides versatile options to efficiently process tree or graph data structures.   In another part, Prolog’s non-determinism and backtracking eases tests of different variations of the program flow without a large level of effort.  A rule-based approach with Prolog allows the characterization of verification goals in a concise and declarative way.  This is why the Prolog programming language is currently being used to do source code verification for embedded aerospace systems \cite{flederer2017source}.  

Multidimensional software correlation can be leveraged in order to collectively analyze more data inputs that single dimensional Software Correlation, but this does not necessarily mean that the results will be more useful or efficient.  Issues exist in the accuracy of the data gained, but on a grander scale because of the increase in the number of inputs.  In terms of efficiency, there are also issues in terms of computing and analyst time required to get though the raw data and explore the results to find the applicable truths.  

\begin{comment}
A common technique to verify programs of a safety critical nature is the analysis of their Abstract Syntax Tree (AST).  Tree structures can be analyzed with the logic programming language Prolog.

\section{Deep Neural Networks}


DU "I'm not sure this section is needed, unless you plan ot advance the state-of-the-art in nural nets.

Authorship attrubution is done in the way today "Single Correlation and Mutiple Correlation...

xyz - smith uses mutiple correlation though hyper regression means or neural network
	more examples
	why using NNets vs traiditional statisitical means
	pros and cons


There are many different combinations of ways to implement inventions in software and even the most powerful of modern computers cannot consider all combinations of how that code might infringe on a patent or identify the original author because of inherent complexity.  This work is still left to human experts using their knowledge and experience and similar to that of factual based evidence research, much of the same highly knowledgeable and experienced skill sets cannot be easily taught or automated. \cite{influence:2009}  This is a problem that many in software forensics are trying to automate by finding an algorithm or simplifying process, but it has not proved to be an easy task.

Deep neural networks (DNN) is a means by which multiple layers between the input and output can be applied in order to model complex non-linear relationships.  For this proposal the aim is to apply this type of analysis in order to speed up the time in which it would normally take an analyst to find/evaluate reliable indicators of malicious software intent, which cutting down on the high false positive rates of traditional single and multidimensional software correlation.  In order to do this, vectors that are expressed as constant maps will be concatenated into sets of weighted layers.  During the training process, the application of the various natural language processing indicators for malicious intent can be used as a parameter that can also updated by backpropagation.  A similar application of neural networks is being applied to software defect prediction in order to show significant improvement over baseline techniques \cite{phan2018convolutional}.

\subsection{Recurrent Neural Network}
A recurrent neural network (RNN) is a specific class of deep neural network where the connections between units can form a directed graph along a sequence that allows analysis for dynamic temporal behavior for a time sequence.  Research has shown that an ensemble of recurrent neural networks are able to predict whether an executable is malicious or benign within the first 5 seconds of execution with 94\% accuracy \cite{rhode2017early}.  Adversarial authorship was not a focus point for this research, but some of the concepts could be used provide a temporal based analysis of the authorship problem.

\subsection{Convolutional Neural Network}
A convolutional neural network (CNN) is a specific class of deep neural network where the network is made up of neurons that have weights and biases.  Within this, each neuron receives some inputs, performs a product and optionally follows it with a non-linearity.  The whole network still expresses a single differentiable score function, an example would be from the raw image pixels on one end to apply class scores at the other end.
\end{comment}

\section{Summary}
All single dimensional software correlation techniques have in inherent weaknesses within the application of authorship attribution for malicious software.  The state of the science needs to be provided a framework of multi-dimensional software correlation that can help spread the sources of attribution across areas of analysis in order to better apply augmented intelligence and allow analysts to navigate the maze of false positives.  

\begin{comment}
DU's resposse to part of your summary 'All software correlation techniques share a weaknesses of difficult in determining is the correct input or inputs being analyzed and is it from a trustworthy source.' = "huh?"

DU comments onlast sentence "ok...so what does this have to do with you?  Need a logical connection to your proposal solution"
\end{comment}

%**********************************************************************
%**********************************************************************
%Chapter Three (CH3)
%**********************************************************************
%**********************************************************************
\chapter{Proposed Solution}
\label{chap:three}
%This research proposes a novel method of identify the features within larger feature set that provide the best %computationally feasible solution to authorship attribution.  We propose applying known and attributed malware inputs into a %framework for analysis in order to identify the best computational efficiency of preforming feature selection for the %purpose of authorship attribution.  

This research proposes a novel approach to malware authorship attribution by identifying those features within a larger feature set of malicious software samples in such a way as to maximize accuracy.  Specifically, we will input a given attributed malware dataset into an existing framework that performs static and dynamic malware analysis.   The results of the analysis are applied to machine learning classifiers that result in all possible feature sets.  We propose to determine the smallest subset of features that maximize accuracy.  


\begin{comment}

The feature sets within malicious software samples will be used to compare the cyber threats actions in a sandboxed environment.  Analysis using Natural Language Processing (NLP) algorithms on key features within feature set families for authorship attribution will be preformed in order find the accuracy of the classifiers.  Based on the accuracy, this research will show the computational efficient feature sets chosen.  This will help analysts identify similar and unique features within malicious software artifacts in order to better apply authorship attribution to currently unattributed samples or threat actors.  Using forensic software analysis to determine the structure and function among malicious software examples can allow for the syntactic differences in implementations to be ignored, but be able to focus on the program's attributable characteristics within feature sets to determine the origin.  Current methods in applying cyber threat attribution will be researched in order to provide a comparison on accuracy.

This research in multidimensional correlation contains three main parts.  Figure 3.1 shows a visual description of the software codebase used in this research identified by different shaded blocks.  The first part labeled APT Malware is on the left side of the figure.  The APT Malware part is the dataset input from which static and dynamic malware analyis will be preformed to identify potential features from the samples.  It includes all raw malware APT samples, stored in folders pertaining to the APT they are attributed to as zip files, and an overview file that provides information and traceability to the identifying Cyber Threat Intelligence (CTI) report.  The second part labeled APT Attribution in the middle of the figure is the software codebase designed to manage the dataflow between samples and results.  It is broken up into two sub-parts that prepare the analysis data to be accepted into the classifiers and the running of the classifiers.  The application of two machine learning classifiers is implemented here in order to measure the accuracy of applying attribution.  The last part is labeled Results on the right side of the figure.  This is used to house the detailed report results in various formats to support the comparison of feature sets when run though the classifiers.  The outputs from this research once complete will be compared with current methods used to attribute cyber threats.  

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/APTAttribution-codebase.png}
	\caption{APTAttribution Codebase \protect\cite{APTAttribution2022}}
	\label{fig:APTAttribution-codebase}
\end{figure}

\begin{comment}
needed to allow analysis to be applied from multiple inputs across a timeline of events.  The Lockheed Martin Cyber Kill Chain allows analysis to take place at different stages with the natural cycle of a cyber attack without having to start from the beginning.  This is important because of the increased use of separate teams for areas of specialty that support the same mission.  Additionally, the state of digital security is such that most intermediate and advanced cyber threat actors are not found to have compromised a system for an extended period of time from when reconnaissance started.  There are the seven steps of the Cyber Kill Chain that describe the actions of a cyber threat: Reconnaissance, Weaponization, Delivery, Exploitation, Installation, Command and Control (C2), and Actions on Objectives \cite{martin2014cyber}.

``The MITRE ATT&CK knowledge base describes cyber adversary behavior and provides a common taxonomy for both offense and defense. It has become a useful tool across many cyber security disciplines to convey threat intelligence, perform testing through red teaming or adversary emulation, and improve network and system defenses against intrusions"  \cite{strom2018mitre}.   This framework can also be used to assist in the application of providence for the tactics and techniques to be define as adversarial behaviors within a lifecycle to a degree where they can be more effectively mapped to attribution.  The MITRE ATT&CK framework provides a granular view of the Delivery, Exploitation, Installation, C2 , and effects within the Cyber Kill Chain. 

The National Vulnerability Database (NVD) is a synchronized and searchable database of publicly disclosed cybersecurity vulnerabilities and exposures \cite{NIST_NVD:2020}.  The NVD consists of Common Vulnerabilities and Exposures (CVE) entries and is extended to include additional data such as fix information, severity scores, and impact ratings. As part of its enhanced information, NVD also provides advanced searching features such as by OS; by vendor name, product name, and/or version number; and by vulnerability type, severity, related exploit range, and impact.
\end{comment}

\end{comment}

\section{Research Goals}
\begin{comment}
The primary goal of this research is to identify the minimum number of features that are required to maximize attribution and minimize computation.  Current capabilities within the area of identification of cyber threat actors (CTAs) based on their attack patterns extracted from cyber threat intelligence (CTI) reports using the distributional semantics technique of Natural Language Processing (NLP) show a precision rate of 83 percent \cite{noor2019machine}.  We aim to identify the computation efficient features in applying the accuracy of authorship attribution for malicious software samples. 
\end{comment}
The overarching goal of this research is to identify the minimum number of features required to attribute a malware sample to its author.  The objectives are 1) to reduce the noise inherent with a large feature set, 2) to increase accuracy, and 3) to reduce the computation resources required to perform authorship attribution.

\begin{comment}
DU comment on research goals "I don't know what this says" = 'map semantic data models in order to determine the linage of malicious software.'  Also, what does 'non-standard environments' "mean?"
	Map data models to apply?

What is the major contribution?  What is the CS link to changing the world?

20200722 - Pulled from first sentence of Research Goals "based on validated cyber threat intelligence and leverage the combined frameworks to enable forensic software analysis"
\end{comment}

\section{Research Plan}
\begin{comment} Look at integration into Ch.2...also need to reference Cuckoo sandbox
The novelty and utility of this research is to lessen the computational work needed to accurately apply cyber threat attribution.  Determining the role authorship plays in the similarity factor of software artifacts based on the providence of artifacts attributed to a specific threat actor enables analysis to react better when new threats emerge or change tactics.  In 2020, HP released a quarterly report on cyber threats that found "29\% of malware captured was previously unknown – due to the widespread use of packers and obfuscation techniques by attackers seeking to evade detection.  It took 8.8 days, on average, for threats to become known by hash to antivirus engines – giving hackers over a week’s ‘head-start’ to further their campaigns." \cite{HP-Bromium2020Q4report}  Research in applying computationally efficient attribution based on a particular software's attributes can be leveraged to react quicker to unknown threats.  If similar attributes are found in two or more different examples, then feature extraction can be used to describe their providence.  Computationally efficient feature extraction can also be applied over a large pool of malicious software examples in order to find trends in currently known capabilities and future focus areas.  The strength of this method for feature extraction is to increase the accuracy of applying cyber threat attribution with fewer resources.  In other words, the idea of applying augmented intelligence by using a novel approach to feature selection can increase the speed of applying cyber threat attribution.  
\end{comment}

\begin{comment}This research plan includes four parts: a dataset used an input, automated analysis platform, reporting infrastructure, and feature selection.  The dataset inputs will be structured in form of Advanced Persistent Threats (APT) that are separated by Country, APT Group, and Malware Family \cite{APTMalware2022}.  Table 3.1 gives a detailed overview of the contents of the APT Malware dataset used in this research.  It provides information on the raw malware samples collected from twelve identified Advanced Persistent Threats, their country of origin, malware family, and number of samples downloaded into the dataset.  
\end{comment}

We plan to conduct this research by first extracting features from a repository of malware samples that are attributed and  in common use by the cybersecurity research community, then selecting those features that provide the greatest accuracy for the least computational cost. 

\subsection{Feature Extraction}

The feature extraction phase consists of selecting the attributed malware dataset, profiling each artifact in the dataset through static and dynamic analysis, and identifying indicators of malicious action.     

Our background research uncovered three malware datasets that contain samples attributed to a specific author:   Laurenza \cite{laurenza2019daptaset}, cyber-research \cite{APTMalware2022}, and Haddadpajouh \cite{haddadpajouh2020mvfcc}.   The Laurenza dataset consists of 19 APT groups and over 2000 malware samples.  The cyber-research dataset contains 3594 malware samples which are related to twelve APT groups and five different nation-states.  The Haddadpajouh dataset consists of roughly 2000 samples and overlaps the cyber-research dataset.  We propose using the cyber-research dataset as it contains the largest number of attributed samples.    Table 3.1 overviews the cyber-research data with the number of malware samples attributed to APT Groups within respective countries. 

\begin{table}[h!]
  \centering
    \caption{APT Malware Dataset}
    \label{tab:table1}
    \begin{adjustbox}{width=\textwidth}
    \begin{tabular}{l|c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      \textbf{Country} & \textbf{APT Group} & \textbf{Family} & \textbf{Sample Size}\\
      \hline
      China & APT 1 &  & 405 \\
      China & APT 10 & i.a. Plugx & 244 \\
      China & APT 19 & Derusbi & 32 \\
      China & APT 21 & TravNet & 106 \\
      Russia & APT 28 & *Bears* & 214 \\
      Russia & APT 29 & *Dukes* & 281 \\
      China & APT 30 & & 164 \\
      North-Korea & DarkHotel & DarkHotel & 273 \\
      Russia & Energetic Bear & Havex & 132 \\
      USA & Equation Group & Fannyworm & 395 \\
      Pakistan & Gorgon Group & Different RATs & 961 \\
      China & Winnti & & 387 \\
      \hline
      Total & & & 3594 \\
    \end{tabular}
  \end{center}
\end{table}

In researching malware analysis tools available that could be used to support the effort of preforming feature extraction of malicious samples, three products were investigated (Cuckoo ref needed, Remnux ref needed, and Bro ref needed).   Cuckoo  is a open source platform that automates malicious file analysis for Windows, OS X, Linux, and Android binaries.  Remnux is a Linux toolkit that assists analysts in reverse engineering malware samples.   Bro is a network-based analysis framework.  We propose using Cuckoo because it encompasses many of Remnux' and Bro's features, has an API that can be interfaced with for automation, and is open source.  

The software code base that controls the Cuckoo sandbox interacts in the following ways:  First, it manages the virtual machine image in which the malware is run.  Second, it executes each malware sample in the sandboxed virtual machine environment.  Third, it collects a variety of information from the sandbox, such as strings, PE sections, identification of packers, shell code, API calls, DLLs accessed, images of UI interaction, network connections, file manipulation, registry hives, and running processes.  Fourth, the analysis data is captured in JSON-formatted files.  Figure 3.1 provides a graphic description of the workflow as the dataset is ingested by the software code base to produce the reports. 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/APTAttribution-codebase-flow.png}
	\caption{Feature extraction workflow  \protect\cite{APTAttribution2022}}
	\label{fig:APTAttribution-codebase}
\end{figure}

In order to prepare the results to be analyzed, cleansing needs to be executed on the raw JSON report files for each sample.  The cleansing consists of two steps:  1) removing encrypted data that is specific to the malware instance but not generally useful to characterizing the malware sample and 2) extracting API calls and arguments.  Following the cleansing process, the reports are ready for feature pruning.  

\subsection{Feature Pruning}

The feature pruning phase sets the stage for identifying the most meaningful combinations of features required for attribution.  This research includes the identification and use of data modeling classification algorithms on the results.  The reason for the use of data modeling classification is to support a structured method for validating the results and promote future analysis by adding additional inputs into this modular framework.  In a comparison of data modeling techniques used in the research of applying attribution to threats the Random Forrest and Deep Neural Network Algorithms excelled \cite{gray2021identifying}.  Within the exploration of more than two classification algorithms, Random Forest (RF) was found to be the most suitable candidates for solving the problem due to their enhanced performance against the other techniques they tested  \cite{hong2018classifying}.  These results agree with additional research in the field: \cite{hendrikse2017effect}, \cite{caliskan2015coding}, \cite{kalgutkar2018android}, \cite{meng2016fine}, \cite{gonzalez2018authorship}.  The parameter values chosen for this data modeling classification algorithm is 100 estimators, meaning that 100 decision trees will run for this model.  Within the exploration other data modeling techniques, Deep Neural Network's showed usefulness for classifying binaries to authors better than Support Vector Machine (SVM) and Conditional Random Fields (CRFs): \cite{meng2018binary}, \cite{rosenberg2017deepapt}, \cite{rosenberg2018end}, \cite{alrabaee2019feasibility}, \cite{alrabaee2019bineye}.  The parameters values chosen for this data modeling classification algorithm is 7 layers of that range from 2000 to 500 nodes, that have a max of 250 iterations through which the data will be run.  These two data modeling classification algorithms show promise in assisting in this research.  Additionally, using more than one data modeling classification algorithm helps to fight bias present in either or the algorithms used.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/JSON_Structure.png}
	\caption{JSON Structure}
	\label{fig:JSON Structure}
\end{figure}

Once the data modeling classification algorithms are selected they will be executed against all filtered and extracted results.  These results are collected that analyzed the accuracy of the classifiers correctly identifying the correct APT group when all features are present.  This give us a control state in which we can experiment using various combinations of feature selection. Then we will prune features in order to identify the best combination that provided a more efficient solution than currently recognized methods.  This method of data pruning is done though jq scripts on the .json formatted results.  An example of this pruning would be iterate over all json formatted results file to separate the data for the WriteProcessMemory API using this piped query string: .behavior.processes[].calls[] | select(.api == "WriteProcessMemory").api.  The ontology of these results is structured into 13 areas described in Figure 3.2.  

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/13_features_reports-vs-data.png}
	\caption{Features}
	\label{fig:Features}
\end{figure}

The info feature contains information on the time/date that the sample submitted, executed, and reported on.  Also, it provides details on Virtual Machine that sample was run on.  Signatures provides a connection between sample execution activities to potential indicators of compromise (IoC).  The target group of features gives target file details, like: name, hash, path, size, and crc checks.  The collection of network information that emanated from the execution of the sample can be viewed in the network feature.  Procmemory shows the details about different regions of the memory with their size, protection level, start and end addresses.  The static feature displays information of the binary and its parts.  Timestamp of when compiled, type of binary, resources used, language, PE sections, PE sections types, memory addresses, and level of entropy.  Dropped provides information on dropped files, hashes, pids, and yara IoC rules flagged.  The behavior collects information on processes, parent/child processes, APIs, and their actions.  Information on size, path, hash, network of items of interest in the memory buffer is contained within the buffer feature.  Debug is where raw logs from sample execution is stored.  Information about the user interface at different points during sample run can be referenced in the screenshot feature.  Strings contains extracted string from the sample.  Metadata includes information about various outputs from the sample being executed.  The scope of these json results include more than 38 million items, 1.35 million being unique, and an upper bound of 2.2 million instances.  The frequency of the total amount of reports and data point present in these thirteen different feature is displayed in Figure 3.3.

Iterations of analysis based on different combinations of features will be used to find the most effective way to apply attribution.  Confusion matrices generated from the data classification algorithms will be used to compare accuracy and drive the iteration process of identifying features that have the greatest rate of positive change for attribution accuracy.  The Validation Section 3.4 describes a specific scenario of feature pruning, analysis, and results.

\begin{comment}
The automated analysis platform used the open source malware analysis sandbox Cuckoo.  All 3594 samples were analyzed in this platform to enable feature set extraction of network, software, user, and other data inputs.  Samples were submitted and reports were returned to the reporting infrastructure though the use of cuckoo REST API.  The average run time for the submission, execution, and collection of the raw reports was around 200 hours.  

The reporting infrastructure is where the raw json formatted reports are housed.  These raw reports are formatted in two different ways in order to preform feature selection that can aid in authorship attribution.  First, the data is filtered in order to remove memory buffer information that does not aid authorship attribution and give the reports a consistent max depth.  Information related to the use of a packer and what level of entropy is present is collected before the memory buffer information is filtered.  Second, API calls and their arguments are extracted in order to provide feature set groupings between reported samples.

With the reports prepared we now analyze the results using two different classifiers with all available features present.  This includes all filtered and extracted data from the raw samples reports.  Results were collected that analyzed the accuracy of the classifiers correctly identifying the correct APT group when all features are present.  This give us a control state in which we can experiment using various combinations of feature selection. Then we will prune features in order to identify the best combination that provided a more efficient solution than currently recognized methods.

In the validation section we describe the process of comparing accuracy from all features to pruned features.  Samples with the combination of most frequent features extracted from the highest scoring malicious sample reports will be used in the initial validation process.  From there we will measure the accuracy of applying attribution from only using these extracted features.  Once accuracy is measured, the most efficient combination of features to apply attribution will be found using this framework.  In other words, the most frequent features will be extracted from the most malicious sample reports and accuracy will be measured from this starting point.  From this point going forward different combinations of feature sets will be used to identify an efficient solution to applying cyber threat attribution.  
\end{comment}

\begin{comment} look for a different reference that uses the same dataset...maybe https://www.hindawi.com/journals/scn/2021/8077220/#conclusions, references (Random Forests (RF) [50], [22], [54], [44] or Deep/Artificial Neural Networks (DNN/ANN) [103], [104], [78], [7], [8]) in https://arxiv.org/abs/2101.06124, or https://cs.ru.nl/~aserban/theses/b_coen_boot.pdf, and http://www.cs.ru.nl/E.Poll/papers/MalwareStateAttribution2019.pdf
This idea is similar to how \cite{oh2009fight} used variable-length fingerprints across a series of instructions to describe how data is used within a function or basic block.  The order and path of data transformations are important and uniquely identifiable, such as in the same way that an mystery author's work can be identified because of key characteristics.  Key characteristics in analyzing the most frequent features extracted from the highest scoring malicious samples are: APIs called, arguments given, PE section details, entropy measurement, and file details.
\end{comment}

\begin{comment}
A focus has been made to standardized formats of Cyber Threat Information (CTI) in order to increase data sharing.  The Malware Information Sharing Platform (MISP) is an open source platform that can be used for gathering, sharing, storing, and correlating a number of structured and unstructured inputs about cyber threats \cite{MISP}.  Examples of common MISP feeds are Indicators of Compromise of targeted attacks, threat intelligence, financial fraud information, and vulnerability information.  We will use the MISP platform for collection and analysis of inputs of authorship attribution based on levels of confidence.  Data from this platform will be used to create training data for an augmented intelligence system that leverages Natural Language Processing.

DU comments on last paraphgraph within 'Research Idea' = "while this is a good 100k-foot descroption, we need a more deailed explanation"

	DU = Change reference display from '[Oh 2009]' to "Oh [2009]"
	
20200722 - Open Standards For Threat Information Sharing
\end{comment}

\section{Research Hypothesis} 
The research hypothesis is ``the multidimensional software correlation mapping technique of feature selection will be more efficient than current recognized methods in applying cyber threat attribution''. The null hypothesis of this research is ``the multidimensional software correlation mapping technique will be as efficient or less efficient than current recognized methods in applying cyber threat attribution''.

\begin{comment}

DU "think of a hypothesis as being a metric by which you will know when you are done.  Consider phrasing the hypothesis in measuable terms.  Also section 3.2 suggests you have two hypothesises"

	Change your research hypothisis
		state your requirement as a yes or no
		what signture based techniquences

		research plan - current validation section Pytorch and Tensor Flow
		null hypothsis - will not preform any better than the current state of the art
\end{comment}

\section{Validation}
This research will be validated by measuring the accuracy of feature sets within a controlled environment.  This controlled environment will be a combination of three main items: a dataset of attributed malware, an automated analytical platform, and two different algorithms for classification.  The dataset includes 3594 samples from 12 different APTs. \cite{APTMalware2022}  These samples were chosen because they are from different APTs supporting different countries and contain a variety of unique information that can be used to test the efficiency of applying cyber threat attribution.  Details on the samples and traceability to cyber threat intelligence report applying attribution is contained within the overview.csv file within the root directory of the dataset.  These samples will be ingested into a sandboxed environment for automated analysis.  Cuckoo Sandbox and its API manage the ingestion of samples, virtual environment, and raw reporting of results.  On average, a full run of all 3594 samples takes around 700 hours to fully complete in the current environment.  These raw results are then formatted so the classifiers can be used to apply attribution.  The classifiers uses two different algorithms to compare results gained through the application of Natural Language Processing.  An initial run of these classifiers was done with all extracted results from the automated analytical platform.  These results are referred to as the control results and take on average 16 hours to complete using the current environment.  Subsequently, the same classifiers will be used to execute runs with specific combinations of extracted feature sets to validate the research. 

Table 3.2 describes the accuracy results from the application of the Random Forrest Classifier (RFC) and Deep Neural Network (DNN) Classifier on all filtered and extracted inputs gained from the static and dynamic malware analysis platform.  These control results are used to describe the accuracy of applying attribution using extracted and filtered results available from the malware analysis environment.  This environment includes the ability to provide identifying features from static/dynamic software analysis, volatile memory, and network actions.  These features are used by the classifiers to apply attribution across the twelve identified Advanced Persistent Threats identified in table 3.1.  There are 3 specific group comparisons that are preformed in this analysis.  The first, APTGrouper is focused on grouping attributed samples from specific APTs.  The second is focused on grouping attributed samples from specific countries.  The third is a combination of countries separated along with grouping based on the malware family.  Within each of these groupers there are two classifiers that are used to measure the accuracy of applying attribution, Random Forrest Classifier (RFC) and Deep Neural Network (DNN) classifier.  The Dataset column describes the source of the filtered or extracted results.  Within the Dataset column, the ``Cuckoo" label designates the filtered results and ``Cuckoo*" designates the extracted results from the environment.  The next three columns represent accuracy results and the standard deviation of those results described in the form of a lowercase Sigma.  In order to adjust for bias within the Groupers Unbalanced, Undersampling, and Oversampling accuracy are recorded and displayed.  Multiple controls runs were executed and results were within 2.5\% accuracy across all runs.

\begin{table}[h!]
    \centering
        \caption{Control Results}
        \label{tab:table2}
        \begin{width=\textwidth}

        \begin{tabular}{l|l|r|r|r}
            \multicolumn{5}{l}{APTGrouper} \\
                     & \textbf{Dataset} & \textbf{Unbalanced} & \textbf{Undersampling} & \textbf{Oversampling} \\ \hline
            \multirow{RFC} & Cuckoo & 0.95 ($\sigma$: 0.01) & 0.82 ($\sigma$: 0.03) & 0.95 ($\sigma$: 0.01) \\
                     & Cuckoo* & 0.40 ($\sigma$: 0.01) & 0.17 ($\sigma$: 0.03) & 0.22 ($\sigma$: 0.02) \\
            \multirow{DNN} & Cuckoo & 0.94 ($\sigma$: 0.00) & 0.81 ($\sigma$: 0.02) & 0.95 ($\sigma$: 0.01) \\
                     & Cuckoo* & 0.40 ($\sigma$: 0.01) & 0.13 ($\sigma$: 0.07) & 0.21 ($\sigma$: 0.03) \\
        \end{tabular}


        \begin{tabular}{l|l|r|r|r}
            \multicolumn{5}{l}{CountryGrouper} \\
                     & \textbf{Dataset} & \textbf{Unbalanced} & \textbf{Undersampling} & \textbf{Oversampling} \\ \hline
            \multirow{RFC} & Cuckoo & 0.96 ($\sigma$: 0.01) & 0.92 ($\sigma$: 0.00) & 0.96 ($\sigma$: 0.00) \\
                     & Cuckoo* & 0.44 ($\sigma$: 0.01) & 0.28 ($\sigma$: 0.01) & 0.28 ($\sigma$: 0.01) \\
            \multirow{DNN} & Cuckoo & 0.97 ($\sigma$: 0.00) & 0.92 ($\sigma$: 0.01) & 0.96 ($\sigma$: 0.00) \\
                     & Cuckoo* & 0.44 ($\sigma$: 0.00) & 0.27 ($\sigma$: 0.01) & 0.28 ($\sigma$: 0.01) \\
        \end{tabular}


        \begin{tabular}{l|l|r|r|r}
            \multicolumn{5}{l}{CountrySeparatedGroupAndFamiliesGrouper} \\
                     & \textbf{Dataset} & \textbf{Unbalanced} & \textbf{Undersampling} & \textbf{Oversampling} \\ \hline
            \multirow{RFC} & Cuckoo & 0.52 ($\sigma$: 0.01) & 0.58 ($\sigma$: 0.11) & 0.58 ($\sigma$: 0.05) \\
                     & Cuckoo* & 0.67 ($\sigma$: 0.01) & 0.35 ($\sigma$: 0.01) & 0.34 ($\sigma$: 0.01) \\
            \multirow{DNN} & Cuckoo & 0.71 ($\sigma$: 0.04) & 0.67 ($\sigma$: 0.04) & 0.63 ($\sigma$: 0.07) \\
                     & Cuckoo* & 0.67 ($\sigma$: 0.01) & 0.34 ($\sigma$: 0.02) & 0.33 ($\sigma$: 0.01) \\
        \end{tabular}
    \end{center}
\end{table}

To test this validation process a data pruning was implemented starting with the highest scoring results from the malware sandbox.  There were a total of 17 malware sample reports that fell into the threat level range of 7-10 and were categorized as very malicious.  Within these 17 high scoring results, 5 distinguishing types of feature sets were contained within these samples.  These feature sets are categorized as: APIs, arguments, PE sections, entropy, and file details.  In total, there were 167 API calls in the 17 samples that were captured.  There were 17 instances of the API WriteProcessMemory being used in reports for this threat level.  Data pruning was executed to isolate on the API WriteProcessMemory calls and associated API arguments from the next round of classification.  Table 3.3 describes the pruned analysis results that show the rate of change in attribution based on two changes to the extracted results from the analysis environment.  The accuracy calculations in red have a rate of accuracy in the extracted fields that shows the efficiency of applying attribution using only this combination of extracted data input.  


\begin{table}[h!]
    \centering
        \caption{API WriteProcessMemory Extracted Results}
        \label{tab:table2}
        \begin{width=\textwidth}

        \begin{tabular}{l|l|r|r|r}
            \multicolumn{5}{l}{APTGrouper} \\
                     & \textbf{Dataset} & \textbf{Unbalanced} & \textbf{Undersampling} & \textbf{Oversampling} \\ \hline
            \multirow{RFC} & Cuckoo & 0.95 ($\sigma$: 0.01) & 0.83 ($\sigma$: 0.01) & 0.95 ($\sigma$: 0.01) \\
                     & Cuckoo* & \color{red}{0.28} ($\sigma$: 0.01) & \color{red}{0.16} ($\sigma$: 0.09) & \color{red}{0.05} ($\sigma$: 0.01) \\
            \multirow{DNN} & Cuckoo & 0.95 ($\sigma$: 0.01) & 0.78 ($\sigma$: 0.02) & 0.95 ($\sigma$: 0.00) \\
                     & Cuckoo* & \color{red}{0.27} ($\sigma$: 0.00) & \color{red}{0.07} ($\sigma$: 0.00) & \color{red}{0.08} ($\sigma$: 0.03) \\
        \end{tabular}

        \begin{tabular}{l|l|r|r|r}
            \multicolumn{5}{l}{CountryGrouper} \\
                     & \textbf{Dataset} & \textbf{Unbalanced} & \textbf{Undersampling} & \textbf{Oversampling} \\ \hline
            \multirow{RFC} & Cuckoo & 0.96 ($\sigma$: 0.01) & 0.93 ($\sigma$: 0.00) & 0.96 ($\sigma$: 0.01) \\
                     & Cuckoo* & \color{red}{0.38} ($\sigma$: 0.00) & \color{red}{0.17} ($\sigma$: 0.06) & \color{red}{0.15} ($\sigma$: 0.03) \\
            \multirow{DNN} & Cuckoo & 0.96 ($\sigma$: 0.01) & 0.93 ($\sigma$: 0.01) & 0.96 ($\sigma$: 0.00) \\
                     & Cuckoo* & \color{red}{0.37} ($\sigma$: 0.00) & \color{red}{0.21} ($\sigma$: 0.10) & \color{red}{0.17} ($\sigma$: 0.03) \\
        \end{tabular}


        \begin{tabular}{l|l|r|r|r}
            \multicolumn{5}{l}{CountrySeparatedGroupAndFamiliesGrouper} \\
                     & \textbf{Dataset} & \textbf{Unbalanced} & \textbf{Undersampling} & \textbf{Oversampling} \\ \hline
            \multirow{RFC} & Cuckoo & 0.53 ($\sigma$: 0.01) & 0.51 ($\sigma$: 0.02) & 0.56 ($\sigma$: 0.01) \\
                     & Cuckoo* & 0.70 ($\sigma$: 0.00) & 0.30 ($\sigma$: 0.00) & 0.30 ($\sigma$: 0.00) \\
            \multirow{DNN} & Cuckoo & 0.71 ($\sigma$: 0.04) & 0.65 ($\sigma$: 0.06) & 0.68 ($\sigma$: 0.07) \\
                     & Cuckoo* & 0.70 ($\sigma$: 0.00) & 0.38 ($\sigma$: 0.16) & 0.46 ($\sigma$: 0.19) \\
        \end{tabular}
    \end{center}
\end{table}

The extracted accuracy results show a significant change in the both classifiers executed for the APTGrouper and CountryGrouper runs for the results associated with the WriteProcessMemory API of the top scoring results from the analysis environment.  Specifically, the average rate of change between the positive accuracy of the Control and API WriteProcessMemory Extracted Results with both classifiers are within 8-11\% for the highlighted Groupers.  Measurements within these results of accuracy between the control and pruned results will be the validation mechanism for this research.

\section{Further Research}
Following the results from the research validation section, the next step is to test and analyze different combinations of feature sets and measure what combination provides the most efficient application of correct cyber threat attribution.  I believe that including feature sets that describe PE sections, entropy, file details, and others can be used to find a more computational efficient way to apply cyber threat attribution.  The timeline for data collection and reporting on this research is planned for the summer and fall of 2022.

\begin{comment}
\begin{table}[]
\begin{tabular}{lll}
Format   & Provider       & URL                                                                  \\
misp     & CIRCL          & https://www.circl.lu/doc/misp/feed-osint                             \\
misp     & Botvrij.eu     & https://www.botvrij.eu/data/feed-osint                               \\
freetext & cinsscore.com  & https://cinsscore.com/list/ci-badguys.txt                            \\
csv      & cybercure.ai   & https://api.cybercure.ai/feed/get\_ips?type=csv                      \\
csv      & cybercure.ai   & https://api.cybercure.ai/feed/get\_url?type=csv                      \\
freetext & IPsum          & https://raw.github.com/stamparm/ipsum/master/levels/2.txt \\
freetext & spamhaus.org   & https://www.spamhaus.org/drop/drop.txt                               \\
freetext & sans.edu       & https://isc.sans.edu/block.txt                                       \\
freetext & multiproxy.org & http://multiproxy.org/txt\_all/proxy.txt                             \\
freetext & multiproxy.org & http://multiproxy.org/txt\_anon/proxy.txt                            \\
freetext & torproject.org & https://check.torproject.org/exit-addresses                          \\
freetext & rutgers.edu    & https://report.cs.rutgers.edu/DROP/attackers                         \\
freetext & sans.edu       & https://isc.sans.edu/feeds/topips.txt                               
\end{tabular}
\end{table}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/MISP_FeedOverlap.PNG}
	\caption{MISP Feed Overlap}
	\label{fig:MISP Feed Overlap}
\end{figure}

The novel framework described earlier in the paper based upon a tiered foundation will be used to apply analysis to like inputs.  The Cyber Kill Chain will be used to describe a threats actions in terms of a foundation based on the stages of reconnaissance, exploitation, and effects.  The MITRE ATT\&CK framework will be used to describe specific action within the stage of exploitation.  Vulnerability details will be applied form input from the NVD.

From this framework, training data will be exported to a augmented intelligence platform designed for NLP and training will take place to enable authorship attribution.



\subsection{Validation Outline}

\begin{outline}[enumerate]
\let\OldOne\1%
\let\OldTwo\2%
\let\OldThree\3%
\renewcommand*{\1}{\normalsize\normalfont\OldOne\bfseries\Large\scshape}%
\renewcommand*{\2}{\normalsize\normalfont\OldTwo\bfseries}%
\renewcommand*{\3}{\normalsize\normalfont\OldThree\small}%
\1 Setup system to analyze malware in datasets A and B
    \2 Collect software's attributes from dataset A, then B
        \3 syntax, functions, inputs, outputs, return values, comments, etc
    \2 Apply 3 level framework
        \3 Cyber Kill Chain (foundation - recon, exploitation, effect)
        \3 MITRE ATTACK (exploitation)
        \3 NVD (effect)
    \2 Apply Cyber Threat Attribution
\1 setup system to compare results 
\end{outline}


DU commnet on 'malicous software samples' =
		"specifics needed: where will they come from (if known)?"
		"how many samples will you need?"
		"type of samples... binaries, or?"

	DU comment "Tensorflow and PyTorch are implementations.  What are the types of ML algorithums you plan to employ?"

	DU comment on 'either confirm or disagree with' = "How are you going to confim/disagree?  Statistical details?"

	validation - prove out the hypothosis is missing
		validation plan - how are we going to measure it (show that the null hyposotis is disproved)

	DU "Schedule of milestones would be much appriciated"

	Milestone Schedule - Months of work to take placee

Notes:
passive voice is a small no-no, use active voice
\end{comment}

\begin{comment}
The research hypothesis will be validated by exploring two approaches to implementing experimental software correlation mapping.  The first entails building and identifying models from malicious software samples using the TensorFlow open source software library for numerical computation using data flow graphs in order to map capabilities and trends.  \cite{kolosnjaji2016deep}  The second building and identifying models from malicious software samples by using the Pytorch open source software library for processing variable length inputs and outputs in order to map capabilities and trends.  \cite{pytorch:2017}

The first method is to implement software correlation mapping could be to emulate mathematical models using TensorFlow in order to apply known semantic characteristics against malicious software samples.  This could be the implementation of a black box technique for adversarial authorship.  The software correlation mapping could be created using the linguistic unit chains created by the authors as part of the identification and trend analysis.  Research into the vector representation of words using TensorFlow has been shown to have a computationally efficient model for learning word embeddings in natural language processing systems.  \cite{mikolov2013efficient}

The second method will be implement by processing variable length inputs and outputs from the malicous samples in order to highlight and them execute trend analysis against the semantic characteristics.  A framework build for binary and static code analysis could be used to create semantically correct representations of capabilities and potentiality motivations with this representation.

For the validation suite of this research a description of what properties that can be used to either confirm or disagree with the research findings are below.  These properties include the application of natural language processing to combine phrases, comments, statements, functions, build details, and other pieces of data in order to understand author's self-interpreted decision trees and apply them to like samples.  For this research the validation suite consists of a scalable testing infrastructure and various families of test cases for common software languages that malicious software is created in.  The test cases aim to identify and resolve differences and similarities within software for which relationships can be applied.  The framework of this test suite is intended to be robust enough to scale up to test cases for the future releases of increasing complexity.  This validation suite, along with review of the relevant literature, aim to ensure the results are reasonable.

These methods will be tested by applying open-source projects on a sample of hardware platforms, to be determined later, where source and compiled code can be obtained to verify semantic changes as well as to allow for refactoring of the mapping process in order to test all these differencing techniques' ability to apply attribution and gauge future capabilities.



\section{Schedule}
% http://texdoc.net/texmf-dist/doc/latex/pgfgantt/pgfgantt.pdf

Below is the schedule for research and validation in the form of a gantt chart.

% \definecolor{barblue}{RGB}{153,204,254}
\definecolor{barblue}{RGB}{246,119,34}
% \definecolor{groupblue}{RGB}{51,102,254}
\definecolor{groupblue}{RGB}{73,110,156}
\definecolor{linkred}{RGB}{165,0,33}
\renewcommand\sfdefault{phv}
\renewcommand\mddefault{mc}
\renewcommand\bfdefault{bc}
\setganttlinklabel{s-s}{START-TO-START}
\setganttlinklabel{f-s}{FINISH-TO-START}
\setganttlinklabel{f-f}{FINISH-TO-FINISH}
\sffamily
\begin{ganttchart}[
    canvas/.append style={fill=none, draw=black!5, line width=.75pt},
    hgrid style/.style={draw=black!5, line width=.75pt},
    vgrid={*1{draw=black!5, line width=.75pt}},
    today=0,
    today rule/.style={
        draw=black!64,
        dash pattern=on 3.5pt off 4.5pt,
        line width=1.5pt
    },
    today label font=\small\bfseries,
    title/.style={draw=none, fill=none},
    title label font=\bfseries\footnotesize,
    title label node/.append style={below=7pt},
    include title in canvas=false,
    bar label font=\mdseries\small\color{black!70},
    bar label node/.append style={left=2cm},
    bar/.append style={draw=none, fill=black!63},
    bar incomplete/.append style={fill=barblue},
    bar progress label font=\mdseries\footnotesize\color{black!70},
    group incomplete/.append style={fill=groupblue},
    group left shift=0,
    group right shift=0,
    group height=.5,
    group peaks tip position=0,
    group label node/.append style={left=.6cm},
    group progress label font=\bfseries\small,
    link/.style={-latex, line width=1.5pt, linkred},
    link label font=\scriptsize\bfseries,
    link label node/.append style={below left=-2pt and 0pt}
    ]{1}{16}
\gantttitle[
    title label node/.append style={below left=7pt and -3pt}
]{WEEKS:\quad1}{1}
\gantttitlelist{2,...,16}{1} \\
\ganttgroup[progress=0]{1. Written Defense of Research}{1}{16} \\
\ganttbar[
    progress=0,
    name=WBS1A
]{\textbf{1.1} Dataset analysis}{1}{6} \\
\ganttbar[
    progress=0,
    name=WBS1B
]{\textbf{1.2} Apply Framework}{7}{12} \\
\ganttbar[
    progress=0,
    name=WBS1C
]{\textbf{1.3} Apply Attribution}{7}{12} \\
\ganttbar[
    progress=0,
    name=WBS1D
]{\textbf{1.4} Compare Results}{13}{16}
\ganttlink[link type=f-s]{WBS1A}{WBS1B}
\ganttlink[link type=s-s]{WBS1B}{WBS1C}
\ganttlink[link type=f-s]{WBS1C}{WBS1D}
\end{ganttchart}
\end{comment}

%**************************************************************************
%**************************************************************************
%FIN
%**************************************************************************
%**************************************************************************

\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{Remote}
\end{document}
